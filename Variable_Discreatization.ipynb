{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20441df5",
   "metadata": {},
   "source": [
    "Discretization, or binning, is the process of transforming continuous variables into discrete\n",
    "variables by creating a set of contiguous intervals, also called bins, that span the range of\n",
    "the variable values. Discretization is used to change the distribution of skewed variables\n",
    "and to minimize the influence of outliers, and hence improve the performance of some\n",
    "machine learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af37b9d3",
   "metadata": {},
   "source": [
    "### 1.Dividing the variable into intervals of equal width\n",
    "- creating bins like 1-10 , 10-20 , ......"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ab54b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from feature_engine.discretisation import EqualWidthDiscretiser\n",
    "\n",
    "## Sckit-learn \n",
    "disc = KBinsDiscretizer(n_bins=10, encode='ordinal',strategy='uniform')\n",
    "disc.fit_transform(df[['LSTAT', 'DIS', 'RM']]) --> returns numpy array \n",
    "## feature engine \n",
    "disc = EqualWidthDiscretiser(bins=10, variables = ['LSTAT', 'DIS','RM'])\n",
    "disc.fit_transform(df[['LSTAT', 'DIS', 'RM']]) --> returns dataframe \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ebc240",
   "metadata": {},
   "source": [
    "### 2.Sorting the variable values in intervals of equal frequency\n",
    "- Equal-frequency discretization divides the values of the variable into intervals that carry the same proportion of observations. The interval width is determined by quantiles, and therefore different intervals may have different widths.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a6ad6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from feature_engine.discretisation import EqualFrequencyDiscretiser\n",
    "\n",
    "## By using sckit-learn \n",
    "disc = KBinsDiscretizer(n_bins=10, encode='ordinal',strategy='quantile')\n",
    "disc.fit_transform(df[['LSTAT', 'DIS', 'RM']]) --> returns numpy array \n",
    "\n",
    "## By using feature engine \n",
    "disc = EqualFrequencyDiscretiser(q=10, variables = ['LSTAT', 'DIS','RM'])\n",
    "disc.fit_transform(df[['LSTAT', 'DIS', 'RM']]) --> returns dataframe \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783cf381",
   "metadata": {},
   "source": [
    "### 3. Performing discretization with k-means clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b033b560",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "disc = KBinsDiscretizer(n_bins=10, encode='ordinal',strategy='kmeans')\n",
    "disc.fit_transform(X_train[['LSTAT', 'DIS', 'RM']])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fd8f41",
   "metadata": {},
   "source": [
    "### 4. Using decision trees for discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec69129",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This makes bins but may have decimal values \n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from feature_engine.discretisation import DecisionTreeDiscretiser\n",
    "\n",
    "## By using Sckit-learn \n",
    "tree_model = DecisionTreeRegressor(max_depth=3, random_state=0)\n",
    "tree_model.fit(X_train['LSTAT'].to_frame(), y_train)\n",
    "X_train['lstat_tree'] = tree_model.predict(X_train['LSTAT'].to_frame())\n",
    "\n",
    "## By using feature engine \n",
    "\n",
    "treeDisc = DecisionTreeDiscretiser(cv=10, scoring='neg_mean_squared_error',\n",
    "                                   variables=['LSTAT', 'RM', 'DIS'],\n",
    "                                   regression=True, param_grid={'max_depth': [1,2,3,4]})\n",
    "\n",
    "train_t = treeDisc.fit_transform(X_train)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
